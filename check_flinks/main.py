# check_flinks/main.py
# author:  ByteWyrm
# date: 2025.5.25 1:20
# TODO: æ£€æµ‹æ‰€æœ‰æä¾›çš„å‹é“¾é“¾æ¥:linkã€avatorã€friends-htmlã€friends-rssã€friends-repo
# Doneï¼šå·²ç»å®ç°æ£€æµ‹jsonéƒ¨åˆ†é“¾æ¥çŠ¶æ€å¹¶ç”ŸæˆæŠ¥å‘Šï¼šlinkã€avator
import os
import json
import time
import requests
from github import Github,GithubException
from concurrent.futures import ThreadPoolExecutor
import re

# é…ç½®æ–‡ä»¶è·¯å¾„
STATUS_FILE = "link_status.json"

def parse_all_links(issue_body):
    """ä» Issue æ­£æ–‡ä¸­æå–å‹é“¾åˆ—è¡¨"""
    links = []
    link_types = {}
    rss_link = None
    repo_link = None
    friends_html = None

    # --------------------------
    # è§£æ JSON éƒ¨åˆ†ï¼ˆlink, avatarï¼‰
    # --------------------------
    json_match = re.search(r'```json\s*({[\s\S]*?})\s*```', issue_body)
    if json_match:
        try:
            config = json.loads(json_match.group(1))
            if config.get("link"):
                links.append(config["link"])
                link_types[config["link"]] = "link"
            if config.get("avatar"):
                links.append(config["avatar"])
                link_types[config["avatar"]] = "avatar"
        except json.JSONDecodeError:
            pass

    # --------------------------
    # è§£æå‹é“¾åœ°å€ï¼ˆfriends-htmlï¼Œå¿…å¡«ï¼‰
    # --------------------------
    # ä¿®æ­£æ­£åˆ™è¡¨è¾¾å¼ï¼ŒåŒ¹é… GitHub æ¸²æŸ“åçš„ HTML ç»“æ„
    html_match = re.search(
        r'name="friends-html"[^>]*value="([^"]+)"',  # åŒ¹é… name å±æ€§
        issue_body
    )
    if html_match and html_match.group(1).strip():
        friends_html = html_match.group(1).strip()
        links.append(friends_html)
        link_types[friends_html] = "friends-html"

    # --------------------------
    # è§£æè®¢é˜…åœ°å€ï¼ˆfriends-rssï¼Œå¯é€‰ï¼‰
    # --------------------------
    rss_match = re.search(
        r'name="friends-rss"[^>]*value="([^"]+)"',
        issue_body
    )
    if rss_match and rss_match.group(1).strip():
        rss_link = rss_match.group(1).strip()
        links.append(rss_link)
        link_types[rss_link] = "rss"

    # --------------------------
    # è§£æå‹é“¾ä»“åº“ï¼ˆfriends-repoï¼Œå¯é€‰ï¼‰
    # --------------------------
    repo_match = re.search(
        r'name="friends-repo"[^>]*value="([^"]+)"',
        issue_body
    )
    if repo_match and repo_match.group(1).strip():
        repo_link = repo_match.group(1).strip()
        links.append(repo_link)
        link_types[repo_link] = "repo"

    # --------------------------
    # å¤„ç†å¯é€‰å­—æ®µæœªå¡«å†™çš„æƒ…å†µ
    # --------------------------
    if not rss_link:
        links.append("æœªæä¾›")
        link_types["æœªæä¾›"] = "rss"
    if not repo_link:
        links.append("æœªæä¾›")
        link_types["æœªæä¾›"] = "repo"

    return links, link_types

def parse_links(issue_body):
    """ä» Issue æ­£æ–‡ä¸­æå–å‹é“¾åˆ—è¡¨"""
    links = []
    link_types = {}

    # è§£æ JSON éƒ¨åˆ†ï¼ˆlink, avatarï¼‰
    json_match = re.search(r'```json\s*({[\s\S]*?})\s*```', issue_body)
    if json_match:
        try:
            config = json.loads(json_match.group(1))
            if config.get("link"):
                links.append(config["link"])
                link_types[config["link"]] = "link"
            if config.get("avatar"):
                links.append(config["avatar"])
                link_types[config["avatar"]] = "avatar"
        except json.JSONDecodeError:
            pass

    return links, link_types

def check_link(url, test_count=5):
    """æ£€æµ‹å•ä¸ªé“¾æ¥çŠ¶æ€ï¼Œæµ‹è¯•å¤šæ¬¡"""
    if url == "æœªæä¾›":
        return {
            "url": url,
            "status": "æœªæä¾›",
            "status_code": "N/A",
            "avg_latency": 0,
            "success_count": 0,
            "fail_count": 0,
            "success": True,  # æ ‡è®°ä¸ºæˆåŠŸä»¥ç®€åŒ–ç»Ÿè®¡
            "error": None,
            "last_check": time.strftime('%Y-%m-%d %H:%M:%S')
        }

    results = []
    for _ in range(test_count):
        try:
            start_time = time.time()
            response = requests.get(
                url,
                timeout=10,
                allow_redirects=True,
                verify=True,
                headers={"User-Agent": "Mozilla/5.0 (GitHub Friend Link Checker)"}
            )
            latency = round(time.time() - start_time, 2)
            results.append({
                "status_code": response.status_code,
                "latency": latency,
                "success": response.ok,
                "error": None
            })
        except Exception as e:
            results.append({
                "status_code": "Error",
                "latency": 0,
                "success": False,
                "error": str(e)
            })

    # è®¡ç®—æˆåŠŸç‡å’Œå¹³å‡å»¶è¿Ÿ
    success_count = sum(1 for res in results if res["success"])
    fail_count = test_count - success_count
    avg_latency = round(sum(res["latency"] for res in results) / max(1, len(results)), 2)

    # ç¡®å®šæœ€ç»ˆçŠ¶æ€
    final_status = "å¯è¿æ¥" if fail_count < 3 else "æ— æ³•è¿æ¥"
    status_code = results[-1]["status_code"] if results else "Unknown"

    return {
        "url": url,
        "status": final_status,
        "status_code": status_code,
        "avg_latency": avg_latency,
        "success_count": success_count,
        "fail_count": fail_count,
        "success": fail_count < 3,
        "error": next((res["error"] for res in results if res["error"]), None),
        "last_check": time.strftime('%Y-%m-%d %H:%M:%S')
    }

def load_status():
    """åŠ è½½å†å²çŠ¶æ€æ•°æ®"""
    if os.path.exists(STATUS_FILE):
        with open(STATUS_FILE, "r") as f:
            return json.load(f)
    return {}

def update_status(results, link_types):
    """æ›´æ–°çŠ¶æ€æ•°æ®ï¼ˆæˆåŠŸæ¬¡æ•°/å¤±è´¥æ¬¡æ•°ï¼‰"""
    status = load_status()
    for res in results:
        key = res["url"]
        if key not in status:
            status[key] = {
                "success": 0, 
                "fail": 0, 
                "type": link_types.get(key, "unknown"),
                "last_check": res["last_check"]
            }
        if res["success"]:
            status[key]["success"] += 1
        else:
            status[key]["fail"] += 1
        status[key]["last_check"] = res["last_check"]
    with open(STATUS_FILE, "w") as f:
        json.dump(status, f, indent=2)
    return status

def generate_report(results, status, link_types):
    """ç”Ÿæˆä¼˜åŒ–çš„ Markdown æŠ¥å‘Š"""
    # ç»Ÿè®¡æˆåŠŸã€å¤±è´¥ã€æœªæä¾›çš„é“¾æ¥æ•°é‡
    success_count = sum(1 for res in results if res["success"] and res["url"] != "æœªæä¾›")
    fail_count = sum(1 for res in results if not res["success"] and res["url"] != "æœªæä¾›")
    optional_missing = sum(1 for res in results if res["url"] == "æœªæä¾›")
    
    report = [
        f"# å‹é“¾çŠ¶æ€æ£€æµ‹æŠ¥å‘Š",
        f"**æ£€æµ‹æ—¶é—´**: {time.strftime('%Y-%m-%d %H:%M:%S')}",
        f"**æ£€æµ‹ç»“æœ**: å…±æ£€æµ‹ {len(results)} ä¸ªé“¾æ¥ï¼Œ{success_count} ä¸ªæˆåŠŸï¼Œ{fail_count} ä¸ªå¤±è´¥ï¼Œ{optional_missing} ä¸ªæœªæä¾›",
        ""
    ]
    
    # éœ€è¦ä¿®å¤çš„é“¾æ¥ï¼ˆæ’é™¤æœªæä¾›çš„é“¾æ¥ï¼‰
    if fail_count > 0:
        report.append("## âš ï¸ éœ€è¦ä¿®å¤çš„é“¾æ¥")
        report.append("| URL | ç±»å‹ | çŠ¶æ€ | å¹³å‡å»¶è¿Ÿ | é”™è¯¯ä¿¡æ¯ |")
        report.append("|-----|------|------|----------|---------|")
        for res in results:
            if not res["success"] and res["url"] != "æœªæä¾›":
                link_type = link_types.get(res["url"], "æœªçŸ¥")
                error_msg = res.get("error", "æ— ") or "æ— "
                row = f"| {res['url']} | {link_type} | {res['status']} | {res['avg_latency']}s | {error_msg} |"
                report.append(row)
        report.append("")
    
    # æ‰€æœ‰é“¾æ¥çŠ¶æ€ï¼ˆåŒ…å«æœªæä¾›çš„é“¾æ¥ï¼‰
    report.append("## æ‰€æœ‰é“¾æ¥çŠ¶æ€")
    report.append("| URL | ç±»å‹ | çŠ¶æ€ | å¹³å‡å»¶è¿Ÿ | æˆåŠŸæ¬¡æ•° | å¤±è´¥æ¬¡æ•° | æœ€åæ£€æµ‹æ—¶é—´ |")
    report.append("|-----|------|------|----------|---------|---------|--------------|")
    for res in results:
        key = res["url"]
        link_type = link_types.get(key, "æœªçŸ¥")
        stats = status.get(key, {"success": 0, "fail": 0, "last_check": "æ— è®°å½•"})
        
        if key == "æœªæä¾›":
            row = f"| {key} | {link_type} | ğŸŸ¡ æœªæä¾› | - | - | - | - |"
        else:
            status_emoji = "âœ…" if res["success"] else "âŒ"
            total_success = stats["success"]
            total_fail = stats["fail"]
            last_check = stats["last_check"]
            row = f"| {key} | {link_type} | {status_emoji} {res['status']} | {res['avg_latency']}s | {total_success} | {total_fail} | {last_check} |"
        report.append(row)
    
    # æ·»åŠ æç¤ºä¿¡æ¯
    if fail_count > 0:
        report.append("\nâš ï¸ **æœ‰é“¾æ¥æ£€æµ‹å¤±è´¥ï¼Œè¯·ä¿®å¤åé‡æ–°æäº¤**")
    else:
        report.append("\nâœ… **æ‰€æœ‰é“¾æ¥æ£€æµ‹é€šè¿‡**")
    
    return "\n".join(report)

def manage_labels(issue_number, is_success):
    """ç®¡ç† Issue æ ‡ç­¾"""
    try:
        g = Github(os.getenv("GITHUB_TOKEN"))
        repo = g.get_repo(os.getenv("GITHUB_REPOSITORY"))
        issue = repo.get_issue(issue_number)
        
        # è·å–å½“å‰æ‰€æœ‰æ ‡ç­¾åç§°
        current_labels = [label.name for label in issue.labels]
        
        # æ¸…ç†æ—§æ ‡ç­¾ï¼ˆä»…åˆ é™¤å­˜åœ¨çš„æ ‡ç­¾ï¼‰
        for label in ["active", "needs-fix"]:
            if label in current_labels:
                issue.remove_from_labels(label)
        
        # æ·»åŠ æ–°æ ‡ç­¾
        new_label = "active" if is_success else "needs-fix"
        issue.add_to_labels(new_label)
    except GithubException as e:
        if e.status == 410:
            print(f"âš ï¸ Issue #{issue_number} å·²è¢«åˆ é™¤ï¼Œè·³è¿‡æ ‡ç­¾æ“ä½œã€‚")
        else:
            raise

if __name__ == "__main__":
    # ä»ç¯å¢ƒå˜é‡è·å– Issue æ•°æ®
    issue_body = os.getenv("ISSUE_BODY")
    issue_number = int(os.getenv("ISSUE_NUMBER"))

    # æå–å¹¶æ£€æµ‹é“¾æ¥
    links, link_types = parse_links(issue_body)
    results = []

    for link in links:
        results.append(check_link(link, test_count=5))
    
    # æ ‡ç­¾ç®¡ç†
    all_success = all(res["success"] for res in results)
    manage_labels(issue_number, all_success)

    # æ›´æ–°çŠ¶æ€å¹¶ç”ŸæˆæŠ¥å‘Š
    status = update_status(results, link_types)
    report = generate_report(results, status, link_types)
    
    # è¾“å‡ºæŠ¥å‘Šåˆ° Artifact å¹¶è¯„è®º
    with open("link_report.md", "w") as f:
        f.write(report)